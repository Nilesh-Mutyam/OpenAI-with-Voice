import React, { useEffect } from 'react';

const VoiceRecognition = ({ onResult }) => {
  useEffect(() => {
    const recognition = new window.SpeechRecognition();
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    recognition.onresult = event => {
      onResult(event.results[0][0].transcript);
    };

    recognition.start();

    return () => {
      recognition.stop();
    };
  }, [onResult]);

  return null;
};

export default VoiceRecognition;


/*
give me line by line explanation for VoiceRecognition.js

Sure, here's a line by line explanation of the code in the VoiceRecognition.js file:

python

import React, { useState, useEffect } from 'react';

This line imports the React library, the useState hook, and the useEffect hook from the React library. The useState hook is a built-in hook in React that allows you to manage state in your functional components. The useEffect hook is a built-in hook in React that allows you to perform side effects in your functional components.

python

import ResponsiveVoice from 'responsivevoice';

This line imports the ResponsiveVoice library, which is a Text-to-Speech library that will be used to read out the response generated by GPT-3.

javascript

const VoiceRecognition = ({ setResponse }) => {

This line declares a new functional component called VoiceRecognition. The component will be a stateless component, since it only needs to render the UI and does not need to manage state. The setResponse function is passed as a prop to the component and will be used to update the value of the response in the state.

scss

  const [isListening, setIsListening] = useState(false);
  const [error, setError] = useState(null);

This block uses the useState hook to manage the state of two variables: isListening and error. The isListening variable will store a Boolean value that indicates whether the voice recognition is currently active or not. The error variable will store any error messages that occur during the voice recognition process.

scss

  useEffect(() => {
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setError('Your browser does not support speech recognition.');
      return;
    }
    const recognition = new SpeechRecognition();
    recognition.interimResults = false;
    recognition.lang = 'en-US';
    recognition.start();
    recognition.onresult = (event) => {
      setIsListening(false);
      const voiceInput = event.results[0][0].transcript;
      setResponse(voiceInput);
      ResponsiveVoice.speak(voiceInput);
    };
    recognition.onerror = (event) => {
      setIsListening(false);
      setError(event.error);
    };
    recognition.onend = () => setIsListening(false);
    setIsListening(true);
  }, [setResponse]);

This is the main useEffect hook in the component. The hook is executed when the component is mounted and whenever the setResponse function changes.

The hook starts by checking if the SpeechRecognition API is available in the user's browser. If it's not available, the setError function is used to set an error message indicating that speech recognition is not supported.

If the SpeechRecognition API is available, a new instance of the SpeechRecognition object is created. The interimResults property is set to false, which means that only the final recognition results will
*/